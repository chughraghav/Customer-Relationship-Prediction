{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KGPDtaP2MKl"
   },
   "source": [
    "# Self Case Study - 1 \n",
    "## Customer Relationship Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MVJ6dAa0uEev",
    "outputId": "2f10acbb-e60c-4e05-b1d0-3bd57e527349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.3 MB 5.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.2.post1\n",
      "    Uninstalling scikit-learn-0.22.2.post1:\n",
      "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
      "Successfully installed scikit-learn-0.24.2 threadpoolctl-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "dTzV_T0VdwyS"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "from prettytable import PrettyTable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lz9iiKXl2kvn"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import six\n",
    "sys.modules['sklearn.externals.six'] = six"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qnBMM0FYZCI"
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AvONbkZV2MKq"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/X_test.pickle', 'rb') as handle:\n",
    "    X_test = pickle.load(handle)\n",
    "columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "yilqqgCQO1lU"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/y_test_appetency.pickle', 'rb') as handle:\n",
    "    y_test_appetency = pickle.load(handle)\n",
    "\n",
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/y_test_churn.pickle', 'rb') as handle:\n",
    "    y_test_churn = pickle.load(handle)\n",
    "\n",
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/y_test_upselling.pickle', 'rb') as handle:\n",
    "    y_test_upselling = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Xkx_-4MgTjJi"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/not_nan_features.pickle', 'rb') as handle:\n",
    "    features = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7fZJMRBNYqHs"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/data_mean.pickle', 'rb') as handle:\n",
    "    data_mean = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "G9jcO7TTt20S"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/ordinal_encoder_clustering.pickle', 'rb') as handle:\n",
    "    ordinal_enocoder_imputation_cluster = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QTW__C4swKgj"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/clusters.pickle', 'rb') as handle:\n",
    "    kmeans_clusters = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZCIsgsnCQIJ",
    "outputId": "7cd233e6-0d71-4606-c673-e9dce3c842cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator PolynomialFeatures from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/polynomail_featurizer.pickle', 'rb') as handle:\n",
    "    polynomail_featurizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yC29v0i-DSVT"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/Feature engg/Appetency/feature_group_200.pickle', 'rb') as handle:\n",
    "    feature_group_200 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YNR9hLwODWvX"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/Feature engg/Appetency/feature_group_50.pickle', 'rb') as handle:\n",
    "    feature_group_50 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Gt2rqpcHybEo"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/average_per_category.pickle', 'rb') as handle:\n",
    "    average_per_category = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "B-NK6W_-_LaZ"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/cat_encodings.pickle', 'rb') as handle:\n",
    "    cat_encodings = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vl6yolK7EBsK",
    "outputId": "71f9e482-5b45-4714-f0de-6294a5091735"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator StandardScaler from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/vanilla_standard_scaler.pickle', 'rb') as handle:\n",
    "    vanilla_standard_scaler = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZkqij_lEEMg",
    "outputId": "b3f74468-7054-4618-efbe-f87c67c41b6f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator StandardScaler from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/poly_standard_scaler.pickle', 'rb') as handle:\n",
    "    poly_standard_scaler = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NeNBdkuIHYwZ",
    "outputId": "b04f5e3b-3c9c-4992-e6c7-1f0d4850299d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator SGDClassifier from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/appetency_model_final.pickle', 'rb') as handle:\n",
    "    appetency_model_final = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eOnALG0RHfcI",
    "outputId": "7a9a126c-8b61-4c9e-9eda-569b8fe29b50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator SGDClassifier from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/churn_model_final.pickle', 'rb') as handle:\n",
    "    churn_model_final = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5BZjqsyHhJ_",
    "outputId": "1eac6f14-2cc5-420f-8be9-a89ce2a2ee70",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator SGDClassifier from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22.2.post1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "with open('/content/drive/MyDrive/Case Study 1/Data/final/upselling_model_final.pickle', 'rb') as handle:\n",
    "    upselling_model_final = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smBVHBH4UNBB"
   },
   "source": [
    "##  Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-3KeHgxHr7OI"
   },
   "outputs": [],
   "source": [
    "def impute_data(X):\n",
    "    '''This method takes raw data(in dataframe format) as input and tuple of imputed data. The imputed data is returned as tuple of (numerical, categorical data)'''\n",
    "    numerical_data = X.iloc[:,:42].fillna(data_mean)\n",
    "    categorical_data = X.iloc[:,42:].fillna('Others')\n",
    "\n",
    "    return (numerical_data, categorical_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "66RU13HbQoje"
   },
   "outputs": [],
   "source": [
    "def defining_clusters(X):\n",
    "    '''This method takes raw data(in dataframe format) as input and returns clustering labels of the input'''\n",
    "    clustering_labels = []\n",
    "    # before imputing data, we need to take care of NaNs\n",
    "    numerical_features, categorical_data = impute_data(X)\n",
    "\n",
    "    # encoding categorical features\n",
    "    ordinal_features = ordinal_enocoder_imputation_cluster.transform(categorical_data)\n",
    "    final_features = np.hstack((numerical_features, ordinal_features))\n",
    "\n",
    "    # applying clustering\n",
    "    for cluster in kmeans_clusters:\n",
    "        clustering_labels.append(cluster.predict(final_features))\n",
    "    return clustering_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "M9G5dyVA1wXv"
   },
   "outputs": [],
   "source": [
    "def featurize(X, clustering_labels):\n",
    "    '''This feature take raw data and clustering_labels as input and returns new featurized data.'''\n",
    "\n",
    "    # 1.Count of NaN in datapoint\n",
    "    X['NaN_Count'] = X.isna().sum(axis = 1)\n",
    "    \n",
    "    # 2.Binary indicator for NaN in a feature\n",
    "    for column in X.columns[0:-1]:\n",
    "        X[column+'_NaN'] = np.where(X[column].isna(),1,0)\n",
    "\n",
    "    # 3. Cluster label\n",
    "    for i in range(len(clustering_labels)):\n",
    "        X['Cluster_'+str(i)] = clustering_labels[i]\n",
    "\n",
    "    # 4. Polynomial Features\n",
    "\n",
    "    ## Before generating polynomial features, we need to impute data.\n",
    "    numerical_data, categorical_data =  impute_data(X)\n",
    "    categorical_data = categorical_data.iloc[:,:30]\n",
    "    \n",
    "    X.iloc[:,42:72] = categorical_data\n",
    "\n",
    "    X_nan_count = X['NaN_Count'].values.reshape(-1,1)\n",
    "\n",
    "    X_clusters = X.iloc[:,-5:].values\n",
    "\n",
    "    X_binary_ind = X.iloc[:,73:145].values\n",
    "\n",
    "    X_polynomail_features = polynomail_featurizer.transform(numerical_data)\n",
    "\n",
    "\n",
    "    # 5. Average value for feature group\n",
    "    ## Feature group with mean under or close to 50\n",
    "    X['feature_group_50_mean'] = X[feature_group_50].mean(axis =1)\n",
    "\n",
    "    ## Feature group with mean under or close to 200\n",
    "    X['feature_group_200_mean'] = X[feature_group_200].mean(axis =1)\n",
    "\n",
    "    X_feature_means = X.iloc[:,-2:].values\n",
    "\n",
    "\n",
    "    # 6. Average value per category\n",
    "    categorical_cols = X.iloc[:,42:72].columns\n",
    "\n",
    "    for col in range(len(categorical_cols)):\n",
    "        X = pd.merge(X,average_per_category[col].iloc[:,:42],how = 'left', on = categorical_cols[col], suffixes = (None, '_'+categorical_cols[col]+'_avg'))\n",
    "    \n",
    "    ## imputing the NaNs generated during last featurization\n",
    "    for col in X.iloc[:,152:].columns:\n",
    "        mean_col = col.split('_')[0]\n",
    "        X[col] = np.where(X[col].isna(), data_mean[mean_col], X[col])\n",
    "\n",
    "    X_averages =  X.iloc[:,152:].values\n",
    "\n",
    "\n",
    "    # Categorical encoding - freq encoding\n",
    "    for col in range(len(categorical_cols)):\n",
    "        X.loc[:,categorical_cols[col]+'_encoding'] = X[categorical_cols[col]].map(cat_encodings[col])\n",
    "    \n",
    "    X.fillna(0,inplace = True)\n",
    "\n",
    "    X_cat_encoding = X.iloc[:,-30:].values\n",
    "\n",
    "    X_vanilla = np.hstack([numerical_data,X_cat_encoding])\n",
    "    \n",
    "    X_poly = np.hstack((X_polynomail_features, X_nan_count, X_clusters, X_feature_means, X_averages, X_cat_encoding))\n",
    "    \n",
    "    X_vanilla = vanilla_standard_scaler.transform(X_vanilla)\n",
    "\n",
    "    X_poly = poly_standard_scaler.transform(X_poly)\n",
    "\n",
    "    X_poly = np.hstack((X_poly, X_binary_ind))\n",
    "\n",
    "    return X_vanilla,X_poly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KpTtFU-uz-pV"
   },
   "outputs": [],
   "source": [
    "def preprocess(X):\n",
    "    '''This function takes raw data as input and returns preprocessed data for modeling.'''\n",
    "    # coverting to dataframe for ease of operations\n",
    "    X =pd.DataFrame(data = X, columns= columns)\n",
    "\n",
    "    # Removing features having NaN count more than 60% of total data.\n",
    "    X =  X.iloc[:,features]\n",
    "\n",
    "    # generating clustering labels\n",
    "    clustering_labels = defining_clusters(X)\n",
    "\n",
    "    # dropping duplicate columns\n",
    "    X =X.drop(['Var220','Var222'], axis = 1)\n",
    "\n",
    "    # featurizing dataset\n",
    "    X_vanilla, X_poly = featurize(X,clustering_labels)\n",
    "\n",
    "    return X_vanilla, X_poly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "Xv2z8d00gVj_"
   },
   "outputs": [],
   "source": [
    "X = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hy1lm9zvgyZb",
    "outputId": "a7760fb3-cea8-4a7c-8401-07fbea3f7275"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 230)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbadWwLngR04"
   },
   "source": [
    "## Final Function 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "iD78eyBNHBEK"
   },
   "outputs": [],
   "source": [
    "def predict(X_vanilla, X_poly):\n",
    "    '''This function takes in 2 dataset input: vanilla and poly and predicts appetency, churn and upselling '''\n",
    "    y_appetency_pred = appetency_model_final.predict(X_poly)\n",
    "    y_churn_pred =  churn_model_final.predict(X_poly)\n",
    "    y_upselling_pred = upselling_model_final.predict(X_vanilla)\n",
    "\n",
    "    return y_appetency_pred, y_churn_pred, y_upselling_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "yoYlMQAXd_3Z"
   },
   "outputs": [],
   "source": [
    "def final(X):\n",
    "    '''This method takes raw data X as input as numpy array and returns prediction as output'''\n",
    "    X_vanilla, X_poly = preprocess(X)\n",
    "\n",
    "    appetency_pred, churn_pred, upselling_pred = predict(X_vanilla, X_poly)\n",
    "    return appetency_pred, churn_pred, upselling_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NL6zUJJJQF8V",
    "outputId": "dba93306-a47f-4d44-d520-99dfec8e160d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.73 s, sys: 538 ms, total: 9.27 s\n",
      "Wall time: 7.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_appetency_pred, y_churn_pred, y_upselling_pred =  final(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGAMENe6sCqH"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "## Final Function 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "I9p3a7RldzwI"
   },
   "outputs": [],
   "source": [
    "def predict(X_vanilla, X_poly, y_test_appetency, y_test_churn, y_test_upselling):\n",
    "    '''This function takes in 2 dataset and class labels and calulates and retuns mean and individual AUC metric'''\n",
    "    y_appetency_pred = appetency_model_final.predict_proba(X_poly)[:,1]\n",
    "    y_churn_pred =  churn_model_final.predict_proba(X_poly)[:,1]\n",
    "    y_upselling_pred = upselling_model_final.predict_proba(X_vanilla)[:,1]\n",
    "\n",
    "    auc_score_appetency = roc_auc_score(y_test_appetency, y_appetency_pred)\n",
    "    auc_score_churn = roc_auc_score(y_test_churn, y_churn_pred)\n",
    "    auc_score_upselling = roc_auc_score(y_test_upselling, y_upselling_pred)\n",
    "\n",
    "    mean_auc = (auc_score_appetency + auc_score_churn + auc_score_upselling) / 3\n",
    "\n",
    "    return auc_score_appetency, auc_score_churn, auc_score_upselling, mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "S9NiWRH-bAAZ"
   },
   "outputs": [],
   "source": [
    "def final(X,y_appetency,y_churn,y_upselling):\n",
    "    '''This function takes data in input X as numpy array and returns auc score for each label and mean auc score as output'''\n",
    "    X_vanilla, X_poly = preprocess(X)\n",
    "\n",
    "    auc_score_appetency, auc_score_churn, auc_score_upselling, mean_auc = predict(X_vanilla, X_poly, y_appetency, y_churn, y_upselling)\n",
    "    return auc_score_appetency, auc_score_churn, auc_score_upselling, mean_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zldf1Qg3Rc50",
    "outputId": "bc6cb0ce-c15b-4ff8-c85b-b9e34573a4d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.41 s, sys: 591 ms, total: 9.01 s\n",
      "Wall time: 7.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "auc_score_appetency,auc_score_churn,auc_score_upselling,mean_auc =  final(X_test, y_test_appetency, y_test_churn, y_test_upselling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "826Nr0efe6lT"
   },
   "outputs": [],
   "source": [
    "x = PrettyTable()\n",
    "x.field_names = [\"Label\", \"AUC Score\",]\n",
    "x.add_row([\"Appetency\", auc_score_appetency])\n",
    "x.add_row([\"Churn\", auc_score_churn])\n",
    "x.add_row([\"Upselling\", auc_score_upselling])\n",
    "x.add_row([\"Mean Score \", mean_auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gNjtJHU5f2Zy",
    "outputId": "bc266a3e-1d10-4ec6-97d1-595690f18e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|    Label    |     AUC Score      |\n",
      "+-------------+--------------------+\n",
      "|  Appetency  | 0.8700550535575369 |\n",
      "|    Churn    | 0.7569458185363356 |\n",
      "|  Upselling  | 0.8857708018142303 |\n",
      "| Mean Score  | 0.8375905579693675 |\n",
      "+-------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
